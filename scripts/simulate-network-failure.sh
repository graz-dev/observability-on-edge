#!/bin/bash

set -e

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

echo -e "${YELLOW}ğŸ”Œ Simulating Satellite Link Loss...${NC}"
echo "=========================================="

# Get the network-chaos pod (privileged, hostNetwork â€” iptables commands affect the node directly)
CHAOS_POD=$(kubectl get pod -n observability -l app=network-chaos \
  -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)

if [ -z "$CHAOS_POD" ]; then
  echo -e "${RED}âŒ network-chaos pod not found. Is the demo running?${NC}"
  exit 1
fi

# Get the OTel Collector pod IP (traffic blocking is per-source-IP so we only
# affect the collector, not kubelet or Prometheus scraping from the hub)
POD_IP=$(kubectl get pod -n observability -l app=otel-collector \
  -o jsonpath='{.items[0].status.podIP}' 2>/dev/null)

if [ -z "$POD_IP" ]; then
  echo -e "${RED}âŒ OTel Collector pod not found. Is the demo running?${NC}"
  exit 1
fi

# Save pod IP so restore-network.sh can reference the same rules
echo "$POD_IP" > /tmp/otel-collector-pod-ip

echo -e "\n${RED}âš ï¸  Blocking OTel Collector (${POD_IP}) â†’ hub backends...${NC}"

# Helper: insert a DROP rule via BOTH iptables backends.
# k3d/k3s may use iptables-nft OR iptables-legacy depending on host kernel.
# Applying to both guarantees the rule is evaluated regardless of which
# backend the kernel's netfilter uses for the FORWARD chain.
_drop() {
  local dport="$1"
  kubectl exec -n observability "$CHAOS_POD" -- sh -c \
    "iptables        -I FORWARD -s ${POD_IP} -p tcp --dport ${dport} -j DROP 2>/dev/null || true
     iptables-legacy -I FORWARD -s ${POD_IP} -p tcp --dport ${dport} -j DROP 2>/dev/null || true"
}

_drop 4317   # Jaeger OTLP gRPC
_drop 9090   # Prometheus remote-write
_drop 3100   # Loki push

# Flush conntrack entries for the collector so that already-ESTABLISHED gRPC
# connections are not kept alive through the conntrack ESTABLISHED bypass.
# Without this, in-flight long-lived connections survive the DROP rule.
# Redirect stdout: conntrack -D prints each deleted entry, which is noisy.
kubectl exec -n observability "$CHAOS_POD" -- \
  conntrack -D -s "$POD_IP" >/dev/null 2>&1 || true

echo -e "\n${GREEN}âœ“ Network failure simulated (NO pod restart â€” collector keeps running)${NC}"
echo -e "${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${RED}  Collector CANNOT reach: Jaeger / Prometheus / Loki${NC}"
echo -e "${RED}  All three backends are unreachable from edge${NC}"
echo -e "${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"

echo -e "\n${YELLOW}ğŸ“Š What is happening right now:${NC}"
echo "  âœ“ Application (vessel sensors) continues running normally"
echo "  âœ“ OTel Collector receives all telemetry from the app"
echo "  âœ“ Fluent Bit still forwards logs to the OTel Collector"
echo "  âœ— OTel Collector cannot export to Jaeger (TCP blocked)"
echo "  âœ— OTel Collector cannot export to Prometheus (TCP blocked)"
echo "  âœ— OTel Collector cannot export to Loki (TCP blocked)"
echo "  âœ“ Data queues to disk at /var/lib/otelcol/file_storage"
echo "  âœ“ Grafana and Jaeger still accessible (on hub node, unaffected)"

echo -e "\n${YELLOW}ğŸ‘€ Open Grafana â†’ 'Edge Pipeline' dashboard â†’ RESILIENCE section:${NC}"
echo "  - 'Export Throughput' drops to zero (traces and logs)"
echo "  - 'Trace Queue Depth' rises (batches accumulating on disk)"
echo "  - Let it run for 90+ seconds for a visible queue drain spike on restore"

echo -e "\n${YELLOW}ğŸ”„ When ready to restore:${NC}"
echo "  ./scripts/restore-network.sh"
echo ""
