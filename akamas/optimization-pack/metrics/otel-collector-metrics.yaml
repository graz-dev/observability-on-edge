metrics:
  # ── Primary objectives (what we minimise) ──────────────────────────────────

  # container_memory_working_set_bytes (cAdvisor):
  #   - what kubectl top reports
  #   - what the kubelet OOM killer uses
  #   - excludes MADV_FREE pages (freed Go heap pages the OS has not yet reclaimed)
  #   → more accurate than otelcol_process_memory_rss for a Go process in K8s,
  #     where Go 1.12+ releases pages with MADV_FREE causing RSS to stay inflated
  #     after GC until the OS is under memory pressure.
  - name: working_set_bytes
    description: Container working set memory (bytes) — K8s OOM killer reference
    unit: bytes
    ## datasourceMetric: 'container_memory_working_set_bytes{pod=~"otel-collector.*", container="otel-collector", namespace="observability"}'

  # otelcol_process_memory_rss: collector self-reported RSS.
  # Kept as a cross-reference metric — inflated by MADV_FREE on Go 1.12+,
  # so NOT used in the objective function. Collected for diagnostics only.
  - name: memory_rss_bytes
    description: Collector process RSS (bytes) — self-reported, includes MADV_FREE pages
    unit: bytes
    ###datasourceMetric: 'otelcol_process_memory_rss{job=~"$JOB$" %FILTERS%}'

  # CPU: rate over the full measurement window via $DURATION$ (Akamas substitutes
  # the configured telemetry duration, currently 600s = 10 min steady-state).
  - name: cpu_millicores
    description: Collector CPU usage (millicores) — rate over full measurement window
    unit: millicores
    #datasourceMetric: 'rate(container_cpu_usage_seconds_total{pod=~"otel-collector.*", container="otel-collector", namespace="observability"}[$DURATION$]) * 1000'

  # ── SLO / safety metrics (KPIs — must not be violated) ─────────────────────

  # Spans dropped by processors (tail-sampler, batch, memory_limiter at processor level).
  # Uses otelcol_processor_dropped_spans — the correct metric for trace signals.
  # $DURATION$ ensures we measure the full steady-state window, not a fixed slice.
  - name: dropped_spans
    description: Spans dropped by processors (increase over measurement window)
    unit: span
    #datasourceMetric: 'increase(otelcol_processor_dropped_spans{job=~"$JOB$" %FILTERS%}[$DURATION$])'

  # Log records dropped by processors.
  - name: dropped_logs
    description: Log records dropped by processors (increase over measurement window)
    unit: logs
    #datasourceMetric: 'increase(otelcol_processor_dropped_log_records{job=~"$JOB$" %FILTERS%}[$DURATION$])'

  # Metric data-points dropped by processors.
  - name: dropped_metric_points
    description: Metric data-points dropped by processors (increase over measurement window)
    unit: points
    #datasourceMetric: 'increase(otelcol_processor_dropped_metric_points{job=~"$JOB$" %FILTERS%}[$DURATION$])'

  # Spans refused at the RECEIVER level by the memory_limiter back-pressure.
  # This is a distinct failure mode from processor-level dropping: when memory
  # exceeds limit_mib + spike_limit_mib the receiver refuses new data before it
  # enters the pipeline at all. Without this KPI, an overly tight memory_limit_mib
  # would appear safe (0 processor drops) while actually losing data at ingestion.
  - name: refused_spans
    description: Spans refused at receiver (memory_limiter back-pressure)
    unit: spans
    #datasourceMetric: 'increase(otelcol_receiver_refused_spans{job=~"$JOB$" %FILTERS%}[$DURATION$])'

  - name: refused_log_records
    description: Log records refused at receiver (memory_limiter back-pressure)
    unit: records
    #datasourceMetric: 'increase(otelcol_receiver_refused_log_records{job=~"$JOB$" %FILTERS%}[$DURATION$])'

  - name: refused_metric_points
    description: Metric data-points refused at receiver (memory_limiter back-pressure)
    unit: points
    #datasourceMetric: 'increase(otelcol_receiver_refused_metric_points{job=~"$JOB$" %FILTERS%}[$DURATION$])'

  # ── Diagnostic / informational (collected but not in the goal) ─────────────

  # Go live heap allocations — tracks GC pressure independently of OS page reclaim.
  - name: heap_alloc_bytes
    description: Go heap live objects (bytes)
    unit: bytes
    #datasourceMetric: 'otelcol_process_runtime_heap_alloc_bytes{job=~"$JOB$" %FILTERS%}'

  # Export throughput — verifies the collector is still processing under all configs.
  # Rate over the full measurement window for consistency with the CPU metric.
  - name: exported_spans_rate
    description: Spans successfully exported (rate/s over measurement window)
    unit: percent
    #datasourceMetric: 'rate(otelcol_exporter_sent_spans{job=~"$JOB$" %FILTERS%}[$DURATION$])'

  # Accepted throughput at receiver — should be stable across experiments.
  # A significant drop signals the collector is rejecting load, not optimising it.
  - name: accepted_spans_rate
    description: Spans accepted by receiver (rate/s over measurement window)
    unit: percent
    #datasourceMetric: 'rate(otelcol_receiver_accepted_spans{job=~"$JOB$" %FILTERS%}[$DURATION$])'
